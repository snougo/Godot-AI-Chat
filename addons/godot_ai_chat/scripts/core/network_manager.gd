@tool
extends Node
class_name NetworkManager


# --- è¯·æ±‚çŠ¶æ€ä¿¡å· ---
# å½“å‘APIæœåŠ¡å™¨æ‹‰å–æ¨¡åž‹è¯·æ±‚æ—¶å‘å‡º
signal get_model_list_request
# åœ¨å‘é€èŠå¤©è¯·æ±‚æ—¶å‘å‡º
signal new_chat_request_sending

# --- æµå¼å“åº”ä¿¡å· ---
# å½“æ”¶åˆ°æ–°çš„æ–‡æœ¬æ•°æ®å—æ—¶å‘å‡º
signal new_stream_chunk_received(chunk_text: String)
# å½“æ•°æ®æµæ­£å¸¸ç»“æŸæ—¶å‘å‡º
signal chat_stream_request_completed
# å½“æ•°æ®æµä¸»åŠ¨è¢«ç”¨æˆ·åœæ­¢æ—¶å‘å‡º
signal chat_stream_request_canceled

# --- éžæµå¼è¯·æ±‚æˆåŠŸä¿¡å· ---
# å½“å‘APIæœåŠ¡å™¨ä¸Šæ‹‰å–æ¨¡åž‹è¯·æ±‚æˆåŠŸæ—¶å‘å‡º
signal connection_check_request_succeeded
# å½“æ¨¡åž‹åˆ—è¡¨æˆåŠŸèŽ·å–å¹¶æ›´æ–°åŽå‘å‡º
signal get_model_list_request_succeeded(model_list: Array)
# å½“æ¨¡åž‹çš„æ€»ç»“æˆåŠŸå®Œæˆä¹‹åŽå‘å‡º
signal summary_request_succeeded(summary_text: String)

# --- è¯·æ±‚å¤±è´¥ä¿¡å· ---
# å½“è¿žçº¿æ£€æŸ¥è¯·æ±‚å¤±è´¥æ—¶å‘å‡º
signal connection_check_request_failed(error: String)
# å½“å‘APIæœåŠ¡å™¨ä¸Šæ‹‰å–æ¨¡åž‹è¯·æ±‚å¤±è´¥æ—¶å‘å‡º
signal get_model_list_request_failed(error: String)
# å½“æ¨¡åž‹æ€»ç»“å¤±è´¥æ—¶å‘å‡º
signal summary_request_failed(error: String)
# å½“èŠå¤©è¯·æ±‚å¤±è´¥æ—¶å‘å‡º
signal chat_request_failed(error: String)

# --- æµå¼æ•°æ®tokenç›¸å…³ä¿¡å· ---
signal chat_usage_data_received(usage_data: Dictionary)
signal prompt_tokens_consumed_on_failure(estimated_tokens: int)

const CONNECTION_CHECK_TIMEOUT: float = 10.0 # APIæœåŠ¡è¿žçº¿æ£€æŸ¥çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

# ç”¨äºŽéžæµå¼çš„APIæœåŠ¡çš„è¿žçº¿æ£€æŸ¥çš„è¯·æ±‚èŠ‚ç‚¹
@onready var connection_check_httprequest: HTTPRequest = $ConnectionCheckHTTPRequest
# ç”¨äºŽéžæµå¼çš„ä»ŽAPIæœåŠ¡å™¨ä¸ŠèŽ·å–æ¨¡åž‹åˆ—è¡¨çš„è¯·æ±‚èŠ‚ç‚¹
@onready var get_model_list_httprequest: HTTPRequest = $GetModelListHTTPRequest
# ç”¨äºŽéžæµå¼çš„å‘æ¨¡åž‹å‘å‡ºå’ŒæŽ¥æ”¶æ€»ç»“
@onready var summary_httprequest: HTTPRequest = $SummaryHTTPRequest
# ç”¨äºŽå¤„ç†æµå¼èŠå¤©å“åº”çš„è‡ªå®šä¹‰HTTPè¯·æ±‚èŠ‚ç‚¹
@onready var chat_streamed_httprequest: ChatStreamedHTTPRequest = $ChatStreamedHTTPRequest

# --- API å‚æ•° (ä»Žè®¾ç½®ä¸­åŠ è½½) ---
var api_provider: String = ""
var api_base_url: String = ""
var api_key: String = ""
var temperature: float = 0.7
var current_model_name: String = ""

var user_prompt: String = ""
var _last_estimated_prompt_tokens: int = 0
var _usage_data_was_received: bool = false


func _ready() -> void:
	# è®¾ç½®å¹¶è¿žæŽ¥ç”¨äºŽè¿žæŽ¥æ£€æŸ¥çš„ä¼ ç»ŸHTTPRequest
	connection_check_httprequest.timeout = CONNECTION_CHECK_TIMEOUT
	connection_check_httprequest.request_completed.connect(self._on_connection_check_request_completed)
	get_model_list_httprequest.timeout = CONNECTION_CHECK_TIMEOUT
	get_model_list_httprequest.request_completed.connect(self._on_get_model_list_request_completed)
	summary_httprequest.timeout = ToolBox.get_plugin_settings().network_timeout
	summary_httprequest.request_completed.connect(self._on_summary_request_completed)
	
	# è¿žæŽ¥æµå¼è¯·æ±‚èŠ‚ç‚¹çš„ä¿¡å·
	if is_instance_valid(chat_streamed_httprequest):
		chat_streamed_httprequest.new_stream_chunk_received.connect(self._on_new_stream_chunk_received)
		chat_streamed_httprequest.stream_request_completed.connect(self._on_chat_stream_request_completed)
		chat_streamed_httprequest.stream_request_canceled.connect(self._on_chat_stream_interrupted)
		chat_streamed_httprequest.stream_request_failed.connect(self._on_chat_stream_interrupted)
		chat_streamed_httprequest.stream_usage_data_received.connect(self._on_stream_usage_data_received)
	else:
		push_error("[NetworkManager] ChatStreamedHTTPRequest Node is not found in the scene tree!")


#==============================================================================
# ## å…¬å…±å‡½æ•° ##
#==============================================================================

# åœ¨å‘é€ç”¨æˆ·çš„æç¤ºè¯å‰å…ˆæ£€æŸ¥APIæœåŠ¡çš„è¿žçº¿æƒ…å†µ
func connection_check(_user_prompt: String) -> bool:
	print("[NetworkManager] API Connection Checking...")
	
	# æ£€æŸ¥è®¾ç½®æ˜¯å¦æœ‰æ•ˆï¼Œå¦‚æžœæ— æ•ˆåˆ™ç›´æŽ¥å¤±è´¥ï¼Œä¸å‘é€è¯·æ±‚
	if not _set_http_request_base_parameters():
		return false
	
	var stream: bool = false
	var headers: PackedStringArray = AiServiceAdapter.get_request_headers(api_provider, api_key, stream)
	var url: String = AiServiceAdapter.get_models_url(api_provider, api_base_url, api_key)
	var error: Error = connection_check_httprequest.request(url, headers, HTTPClient.METHOD_GET)
	
	if error == OK:
		emit_signal("connection_check_request_succeeded", _user_prompt)
		return true
	else:
		# å¦‚æžœè¿žçº¿æ£€æŸ¥å¤±è´¥ï¼Œåˆ™äº¤ç”±APIè¿žçº¿æ£€æŸ¥ä¿¡å·å›žè°ƒå‡½æ•°å¤„ç†é”™è¯¯
		return false


# ç”¨äºŽä»ŽAPIæœåŠ¡å™¨ä¸ŠèŽ·å–æ¨¡åž‹åˆ—è¡¨å¹¶éªŒè¯APIè®¾ç½®
func get_model_list_from_api_service() -> void:
	print("[NetworkManager] Geting Model List from API Service...")
	emit_signal("get_model_list_request")
	
	# æ£€æŸ¥è®¾ç½®æ˜¯å¦æœ‰æ•ˆï¼Œå¦‚æžœæ— æ•ˆåˆ™ç›´æŽ¥å¤±è´¥ï¼Œä¸å‘é€è¯·æ±‚
	if not _set_http_request_base_parameters():
		return
	
	var stream: bool = false
	var headers: PackedStringArray = AiServiceAdapter.get_request_headers(api_provider, api_key, stream)
	var url: String = AiServiceAdapter.get_models_url(api_provider, api_base_url, api_key)
	get_model_list_httprequest.request(url, headers, HTTPClient.METHOD_GET)


# å‘é€ä¸€ä¸ªæ–°çš„èŠå¤©è¯·æ±‚ï¼Œå¹¶æœŸæœ›ä¸€ä¸ªæµå¼å“åº”ã€‚
func new_chat_stream_request(_context_for_ai: Array) -> void:
	if current_model_name.is_empty():
		emit_signal("chat_request_failed", "No AI model selected.")
		return
	
	# æ£€æŸ¥è®¾ç½®æ˜¯å¦æœ‰æ•ˆï¼Œå¦‚æžœæ— æ•ˆåˆ™ç›´æŽ¥å¤±è´¥ï¼Œä¸å‘é€è¯·æ±‚
	if not _set_http_request_base_parameters():
		return
	
	# åªæœ‰åœ¨ API ä¸æ˜¯ Gemini æ—¶æ‰æ‰§è¡Œæœ¬åœ°ä¼°ç®—ï¼Œä»¥é¿å…é‡å¤è®¡ç®—
	# Gemini ä¼šé€šè¿‡æµè¿”å›žç²¾ç¡®çš„ token æ•°ï¼Œæˆ‘ä»¬åº”è¯¥åªä½¿ç”¨é‚£ä¸ªã€‚
	if api_provider != "Google Gemini":
		_last_estimated_prompt_tokens = ToolBox.estimate_tokens_for_messages(_context_for_ai)
	else:
		# Gemini ä¾èµ– API è¿”å›žçš„ç²¾ç¡®å€¼
		_last_estimated_prompt_tokens = 0
	
	_usage_data_was_received = false
	_set_http_request_base_parameters()
	# è®¾ç½® stream=true æ¥è¯·æ±‚æµå¼è¾“å‡º
	var stream: bool = true 
	var headers: PackedStringArray = AiServiceAdapter.get_request_headers(api_provider, api_key, stream)
	var body_dict: Dictionary = AiServiceAdapter.build_chat_request_body(api_provider, current_model_name, _context_for_ai, temperature, stream)
	var url: String = AiServiceAdapter.get_chat_url(api_provider, api_base_url, current_model_name, api_key, stream)
	
	emit_signal("new_chat_request_sending")
	
	if is_instance_valid(chat_streamed_httprequest):
		chat_streamed_httprequest.start_new_stream_request(url, headers, JSON.stringify(body_dict), api_provider)
	else:
		emit_signal("chat_request_failed", "ChatStreamedHTTPRequest Node is not found in the scene tree!")


# åœæ­¢å½“å‰çš„æµå¼è¯·æ±‚
func cancel_stream_request() -> void:
	if is_instance_valid(chat_streamed_httprequest):
		chat_streamed_httprequest.cancel_current_stream_request()


# æ›´æ–°å½“å‰é€‰æ‹©çš„æ¨¡åž‹åç§°ã€‚
func update_model_name(new_model_name: String) -> void:
	current_model_name = new_model_name


# å‘èµ·ä¸€ä¸ªéžæµå¼çš„æ€»ç»“è¯·æ±‚
func request_summary(chat_history: Array) -> void:
	if current_model_name.is_empty():
		emit_signal("summary_request_failed", "No AI model selected for summarization.")
		return
	
	if not _set_http_request_base_parameters():
		return
	
	var settings: PluginSettings = ToolBox.get_plugin_settings()
	var summarization_prompt: String = settings.summarization_prompt
	
	# æ ¼å¼åŒ–åŽ†å²è®°å½•ä¸ºMarkdownæ–‡æœ¬
	var history_text: String = ""
	for message in chat_history:
		if message.role == "system": continue
		
		match message.role:
			"user": history_text += "### ðŸ§‘â€ðŸ’» User\n"
			"assistant": history_text += "### ðŸ¤– AI Response\n"
			"tool": history_text += "### âš™ï¸ Tool Output\n"
		
		history_text += message.content + "\n\n>------------\n\n"
	
	# æž„å»ºè¯·æ±‚çš„ä¸Šä¸‹æ–‡
	var context_for_summary: Array = [
		{"role": "system", "content": summarization_prompt},
		{"role": "user", "content": history_text.strip_edges()}
	]
	
	var stream: bool = false # æ˜Žç¡®æŒ‡å®šä¸ºéžæµå¼
	var headers: PackedStringArray = AiServiceAdapter.get_request_headers(api_provider, api_key, stream)
	var body_dict: Dictionary = AiServiceAdapter.build_chat_request_body(api_provider, current_model_name, context_for_summary, temperature, stream)
	var url: String = AiServiceAdapter.get_chat_url(api_provider, api_base_url, current_model_name, api_key, stream)
	
	summary_httprequest.request(url, headers, HTTPClient.METHOD_POST, JSON.stringify(body_dict))


#==============================================================================
# ## å†…éƒ¨å‡½æ•° ##
#==============================================================================

# ä»Žæ’ä»¶è®¾ç½®æ–‡ä»¶åŠ è½½æœ€æ–°çš„APIå‚æ•°
func _set_http_request_base_parameters() -> bool:
	var plugin_settings: PluginSettings = ToolBox.get_plugin_settings()
	api_provider = plugin_settings.api_provider
	api_base_url = plugin_settings.api_base_url
	api_key = plugin_settings.api_key
	temperature = plugin_settings.temperature
	
	# åŸºæœ¬çš„è®¾ç½®éªŒè¯
	if api_provider.contains("Google Gemini") and not api_base_url.contains("googleapis"):
		emit_signal("connection_check_request_failed", "API Provider is Gemini but API Address seems incorrect.")
		return false
	if api_provider.contains("OpenAI-Compatible") and api_base_url.contains("googleapis"):
		emit_signal("connection_check_request_failed", "API Provider is OpenAI-Compatible but API Address seems incorrect.")
		return false
	if api_base_url.is_empty():
		emit_signal("connection_check_request_failed", "API Base Url is not set in Settings.")
		return false
	if api_key.is_empty() and api_base_url != "http://127.0.0.1:1234":
		emit_signal("connection_check_request_failed", "API Key is not set in Settings.")
		return false
	
	return true


# ç»Ÿä¸€å¤„ç†å’Œæ ¼å¼åŒ–å„ç§ç½‘ç»œè¯·æ±‚å¤±è´¥çš„åŽŸå› 
func _handle_request_failure(_result: HTTPRequest.Result, _response_code: int, _body: PackedByteArray) -> String:
	var error_message: String
	match _result:
		HTTPRequest.RESULT_TIMEOUT: error_message = "Request timed out. Check your network or increase the timeout in settings."
		HTTPRequest.RESULT_CANT_CONNECT: error_message = "Connection failed. Is the API URL correct and the server running?"
		HTTPRequest.RESULT_CANT_RESOLVE: error_message = "Cannot resolve hostname. Is the API URL spelled correctly?"
		HTTPRequest.RESULT_CONNECTION_ERROR: error_message = "Connection error. A stable data transfer could not be established."
		HTTPRequest.RESULT_TLS_HANDSHAKE_ERROR: error_message = "TLS handshake failed. The URL might need 'http' instead of 'https', or the server certificate is invalid."
		HTTPRequest.RESULT_REDIRECT_LIMIT_REACHED: error_message = "Redirect limit reached. The API URL might be misconfigured."
		HTTPRequest.RESULT_REQUEST_FAILED: error_message = "Request failed. The engine failed to send the request."
		HTTPRequest.RESULT_BODY_SIZE_LIMIT_EXCEEDED: error_message = "Response body size limit exceeded. The response from the server was too large."
	
	if error_message.is_empty() and _response_code > 0:
		match _response_code:
			400: error_message = "Bad Request (HTTP 400). The request may be malformed."
			401: error_message = "Unauthorized (HTTP 401). Check if your API Key is correct and valid."
			403: error_message = "Forbidden (HTTP 403). You don't have permission to access this resource. Check API Key permissions."
			404: error_message = "Not Found (HTTP 404). The API endpoint could not be found. Check the API URL."
			429: error_message = "Too Many Requests (HTTP 429). You have hit the API rate limit. Please wait and try again later."
			500: error_message = "Internal Server Error (HTTP 500). The API provider's server had a problem."
			503: error_message = "Service Unavailable (HTTP 503). The API provider's service is temporarily down."
			_:   error_message = "Request failed (HTTP %d)." % _response_code
		
		if not _body.is_empty():
			var reason = ""
			var response_text = _body.get_string_from_utf8()
			var json_data = JSON.parse_string(response_text)
			if json_data:
				if json_data is Dictionary:
					if json_data.has("error"):
						if json_data["error"] is Dictionary:
							if json_data["error"].has("message"):
								reason = str(json_data["error"]["message"])
					elif json_data.has("message"):
						reason = str(json_data["message"])
				elif json_data is String:
					reason = json_data
			else:
				reason = response_text.left(200) + ("..." if response_text.length() > 200 else "")
			if not reason.is_empty(): error_message += "\nReason: %s" % reason
	elif error_message.is_empty():
		error_message = "An unknown network error occurred (Result code: %d)" % _result
	
	return error_message


#==============================================================================
# ## ä¿¡å·å›žè°ƒå‡½æ•° ##
#==============================================================================

# å¤„ç†APIæœåŠ¡è¿žçº¿æ£€æŸ¥è¯·æ±‚å®Œæˆçš„äº‹æƒ…
func _on_connection_check_request_completed(_result: HTTPRequest.Result, _response_code: int, _headers: PackedStringArray, _body: PackedByteArray) -> void:
	if not (_result == HTTPRequest.RESULT_SUCCESS and _response_code == 200):
		var err_msg: String = _handle_request_failure(_result, _response_code, _body)
		emit_signal("connection_check_request_failed", err_msg)


# å¤„ç†æ¨¡åž‹åˆ—è¡¨èŽ·å–è¯·æ±‚å®Œæˆçš„äº‹ä»¶
func _on_get_model_list_request_completed(_result: HTTPRequest.Result, _response_code: int, _headers: PackedStringArray, _body: PackedByteArray) -> void:
	if _result == HTTPRequest.RESULT_SUCCESS and _response_code == 200:
		var model_data_array: Array = AiServiceAdapter.parse_models_response(api_provider, _body)
		var model_list: Array[String] = []
		
		for model_info in model_data_array:
			if typeof(model_info) == TYPE_DICTIONARY:
				if api_provider == "OpenAI-Compatible" and model_info.has("id"):
					model_list.append(model_info.id)
				elif api_provider == "Google Gemini" and model_info.has("name"):
					# Geminiæ¨¡åž‹åç§°éœ€è¦ç§»é™¤ "models/" å‰ç¼€
					model_list.append(model_info.name.trim_prefix("models/"))
		
		model_list.sort()
		emit_signal("get_model_list_request_succeeded", model_list)
	else:
		var err_msg: String = _handle_request_failure(_result, _response_code, _body)
		emit_signal("get_model_list_request_failed", err_msg)


# æ–°å¢žï¼šå¤„ç†æ€»ç»“è¯·æ±‚å®Œæˆçš„äº‹ä»¶
func _on_summary_request_completed(_result: HTTPRequest.Result, _response_code: int, _headers: PackedStringArray, _body: PackedByteArray) -> void:
	if _result == HTTPRequest.RESULT_SUCCESS and _response_code == 200:
		var summary_text: String = AiServiceAdapter.parse_non_stream_chat_response(api_provider, _body)
		if summary_text.begins_with("[ERROR]"):
			emit_signal("summary_request_failed", summary_text)
		else:
			emit_signal("summary_request_succeeded", summary_text)
	else:
		var err_msg: String = _handle_request_failure(_result, _response_code, _body)
		emit_signal("summary_request_failed", err_msg)


# æ”¶åˆ°æµå¼æ•°æ®å—æ—¶ï¼Œç›´æŽ¥è½¬å‘ä¿¡å·
func _on_new_stream_chunk_received(chunk_text: String):
	emit_signal("new_stream_chunk_received", chunk_text)


# æµå¼ä¼ è¾“æ­£å¸¸ç»“æŸæ—¶ï¼Œç›´æŽ¥è½¬å‘ä¿¡å·
func _on_chat_stream_request_completed():
	# å¦‚æžœæµæ­£å¸¸ç»“æŸï¼Œä½†æˆ‘ä»¬ä»Žæœªæ”¶åˆ°è¿‡çœŸå®žçš„ usage æ•°æ®ï¼Œ
	# è¿™æ„å‘³ç€æˆ‘ä»¬è¿žæŽ¥çš„æ˜¯ä¸€ä¸ªä¸æ”¯æŒæ­¤åŠŸèƒ½çš„æœåŠ¡ã€‚
	# åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¿…é¡»ä½¿ç”¨ä¼°ç®—å€¼ä½œä¸ºå›žé€€ã€‚
	if not _usage_data_was_received and _last_estimated_prompt_tokens > 0:
		print("[NetworkManager] Stream completed without usage data. Committing estimated tokens.")
		emit_signal("prompt_tokens_consumed_on_failure", _last_estimated_prompt_tokens)
	
	# æ¸…ç†ä¼°ç®—å€¼ï¼Œæ— è®ºæ˜¯å¦ä½¿ç”¨
	_last_estimated_prompt_tokens = 0
	
	emit_signal("chat_stream_request_completed")


# æµå¼æ•°æ®ä¼ è¾“å®Œæ¯•åŽå‘é€ä¿¡å·
func _on_stream_usage_data_received(usage_data: Dictionary) -> void:
	print("[DEBUG 2] NetworkManager: Forwarding usage data: ", usage_data)
	_usage_data_was_received = true
	emit_signal("chat_usage_data_received", usage_data)


# æµå¼æ•°æ®ä¼ è¾“ä¸­æ–­æ—¶å‘é€ä¿¡å·
func _on_chat_stream_interrupted(error_message: String = ""):
	if _last_estimated_prompt_tokens > 0:
		emit_signal("prompt_tokens_consumed_on_failure", _last_estimated_prompt_tokens)
		_last_estimated_prompt_tokens = 0
	
	if not error_message.is_empty():
		emit_signal("chat_request_failed", error_message)
	else:
		emit_signal("chat_stream_request_canceled")
